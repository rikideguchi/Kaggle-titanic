{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import KFold, train_test_split\nimport itertools\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/titanic/test.csv')\ntrain = pd.read_csv('../input/titanic/train.csv')\ngender_submission = pd.read_csv('../input/titanic/gender_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train.drop(['Survived'], axis = 1)\ntrain_y = train['Survived']\n\ntest_x = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in ['Sex', 'Embarked']:\n    le = LabelEncoder()\n    le.fit(train_x[c].fillna('NA'))\n    train_x[c] = le.transform(train_x[c].fillna('NA'))\n    test_x[c] = le.transform(test_x[c].fillna('NA'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_x.drop(['PassengerId', 'Name', 'Ticket', 'Cabin',], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = test_x.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(n_estimators=20, random_state=71)\nmodel.fit(train_x, train_y)\n\npred = model.predict_proba(test_x)[:, 1]\npred_label = np.where(pred > 0.5, 1, 0)\n\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\nsubmission.to_csv('submission_first.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_accuracy = []\nscores_logloss = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=4, shuffle = True, random_state=71)\nfor tr_idx, va_idx in kf.split(train_x):\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n    \n    model = XGBClassifier(n_estimators = 20, random_state = 71)\n    model.fit(tr_x, tr_y)\n    \n    va_pred = model.predict_proba(va_x)[:, 1]\n    \n    logloss = log_loss(va_y, va_pred)\n    accuracy = accuracy_score(va_y, va_pred>0.5)\n    \n    scores_logloss.append(logloss)\n    scores_accuracy.append(accuracy)\n\nlogloss = np.mean(scores_logloss)\naccuracy = np.mean(scores_accuracy)\nprint(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')\n                                     \n                              ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_space = {\n    'max_depth': [3, 5, 7], \n    'min_child_weight': [1.0, 2.0, 4.0]\n}\n\nparam_combinations = itertools.product(param_space['max_depth'], param_space[\"min_child_weight\"])\n\nparams = []\nscores = []\n\nfor max_depth, min_child_weight in param_combinations:\n    \n    score_folds = []\n    kf = KFold(n_splits=4, shuffle=True, random_state=123456)\n    for tr_idx, va_idx in kf.split(train_x):\n        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n        \n        model = XGBClassifier(n_estimators=20, random_state=71, \n                              max_depth=max_depth, min_child_weight=min_child_weight)\n        model.fit(tr_x, tr_y)\n        \n        va_pred = model.predict_proba(va_x)[:, 1]\n        logloss = log_loss(va_y, va_pred)\n        score_folds.append(logloss)\n        \n    score_mean = np.mean(score_folds)\n    \n    params.append((max_depth, min_child_weight))\n    scores.append(score_mean)\n    \nbest_idx = np.argsort(scores)[0]\nbest_param = params[best_idx]\nprint(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}